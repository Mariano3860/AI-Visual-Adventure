{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "acf06db2a7dd4634bfc1f5bddf87b9b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_130102dcee2940c5b82e0436f3d6574d",
              "IPY_MODEL_efa4b511f84e4a949f850306385ecaa3",
              "IPY_MODEL_120fbe5def1d42f18e55d68530e83b12"
            ],
            "layout": "IPY_MODEL_780280082f9c41e3b12c7d38d57edd3f"
          }
        },
        "130102dcee2940c5b82e0436f3d6574d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_05d5f48f674449ff82bc7be0c3e2f25c",
            "placeholder": "​",
            "style": "IPY_MODEL_40f34c9283494c39b9abbbfd0ccf0d98",
            "value": "Loading pipeline components...: 100%"
          }
        },
        "efa4b511f84e4a949f850306385ecaa3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aa230c54985842efb51c51789a7ad1fc",
            "max": 7,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9b66b584c24f436b9f72a936cbf56d32",
            "value": 7
          }
        },
        "120fbe5def1d42f18e55d68530e83b12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e1f364a47f754f45899cfc5bdbd630ec",
            "placeholder": "​",
            "style": "IPY_MODEL_0d74383f6ff046b6aae06fc6b0c29d9e",
            "value": " 7/7 [00:02&lt;00:00,  2.99it/s]"
          }
        },
        "780280082f9c41e3b12c7d38d57edd3f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "05d5f48f674449ff82bc7be0c3e2f25c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40f34c9283494c39b9abbbfd0ccf0d98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aa230c54985842efb51c51789a7ad1fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b66b584c24f436b9f72a936cbf56d32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e1f364a47f754f45899cfc5bdbd630ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d74383f6ff046b6aae06fc6b0c29d9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mariano3860/AI-Visual-Adventure/blob/main/AI_Visual_Adventure.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -qqq install transformers diffusers Pillow accelerate opencv-python rembg optimum --progress-bar off"
      ],
      "metadata": {
        "id": "xU2VE6El34vM",
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e535ea7-a551-47ad-f341-30fc3f62454a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for optimum (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q https://github.com/PanQiWei/AutoGPTQ/releases/download/v0.4.2/auto_gptq-0.4.2+cu118-cp310-cp310-linux_x86_64.whl\n",
        "!BUILD_CUDA_EXT=0 pip install -qqq auto_gptq-0.4.2+cu118-cp310-cp310-linux_x86_64.whl --progress-bar off"
      ],
      "metadata": {
        "id": "3c2cGl1-LK7Z"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title UTF-8 problems\n",
        "# import locale\n",
        "# locale.getpreferredencoding = lambda: \"UTF-8\""
      ],
      "metadata": {
        "cellView": "form",
        "id": "U04gZJ7WYzE-"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from os import pipe2\n",
        "# @title img_ai_helper.py\n",
        "# img_ai_helper.py\n",
        "import torch\n",
        "from diffusers import DiffusionPipeline\n",
        "from huggingface_hub import login\n",
        "import rembg\n",
        "import re\n",
        "\n",
        "# If pixel-art-xl lora, need base-model: \"stabilityai/stable-diffusion-xl-base-1.0\"\n",
        "# pipe.load_lora_weights(\"nerijs/pixel-art-xl\", weight_name=\"pixel-art-xl.safetensors\")\n",
        "\n",
        "def model_pipe(base_model_id, lora=None):\n",
        "    use_access_token = base_model_id.startswith(\"marian3860\")\n",
        "    if use_access_token:\n",
        "        access_token = \"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\"\n",
        "        login(token=access_token)\n",
        "    pipe = DiffusionPipeline.from_pretrained(\n",
        "            base_model_id,\n",
        "            variant=\"fp16\",\n",
        "            torch_dtype=torch.float16\n",
        "        ).to(\"cuda\")\n",
        "    pipe.enable_vae_tiling()\n",
        "    # pipe.enable_xformers_memory_efficient_attention()\n",
        "    pipe.enable_attention_slicing()\n",
        "    # pipe.enable_sequential_cpu_offload() - slower, use more cpu over gpu\n",
        "    if (lora):\n",
        "      pipe.load_lora_weights(lora)\n",
        "    # Disables safety checks\n",
        "    def disabled_safety_checker(images, clip_input):\n",
        "        if len(images.shape) == 4:\n",
        "            num_images = images.shape[0]\n",
        "            return images, [False] * num_images\n",
        "        else:\n",
        "            return images, False\n",
        "\n",
        "    pipe.safety_checker = disabled_safety_checker\n",
        "    return pipe\n",
        "\n",
        "\n",
        "def generate_character_image(character_info):\n",
        "    prompt = f\"{character_info}, full body, game character, 100% white background, pixelart\"\n",
        "    n_steps = 30\n",
        "    negative_prompt = \"text, wrong, watermark, fog\"\n",
        "    num_samples = 1\n",
        "    height = 512\n",
        "    width = 256\n",
        "    guidance_scale = 7\n",
        "    generator = torch.Generator(device='cpu')\n",
        "    seed = generator.seed()\n",
        "    torch.manual_seed(seed)\n",
        "    mini_sd_pipe = \"marian3860/miniSD\"\n",
        "    pipe = model_pipe(mini_sd_pipe)\n",
        "    image = pipe(\n",
        "        prompt=prompt,\n",
        "        height=height,\n",
        "        width=width,\n",
        "        num_inference_steps=n_steps,\n",
        "        negative_prompt=negative_prompt,\n",
        "        num_images_per_prompt=num_samples,\n",
        "        guidance_scale=guidance_scale,\n",
        "        generator=generator,\n",
        "    ).images[0]\n",
        "    prompt = sanitize_filename(prompt.strip())\n",
        "    try:\n",
        "      image.save(f\"{prompt}-{seed}.png\")\n",
        "    except OSError as e:\n",
        "        print(f\"Error saving with sanitized filename: {e}\")\n",
        "        image.save(f\"Image-{seed}.png\")\n",
        "    del pipe\n",
        "    torch.cuda.empty_cache()\n",
        "    return image\n",
        "\n",
        "\n",
        "def generate_bg_image(story, width=1024, height=1024):\n",
        "    prompt = f\"Full colored, first person, panoramic view\" \\\n",
        "             f\"detailed scene that extends horizontally canvas, \"\\\n",
        "             f\"{story}\"\n",
        "    n_steps = 25\n",
        "    negative_prompt = f\"text, wrong, watermark, fog, miniature, person, \"\\\n",
        "                      f\"black and white, people, characters, human\"\n",
        "    num_samples = 1\n",
        "    guidance_scale = 7\n",
        "    generator = torch.Generator(device='cpu')\n",
        "    seed = generator.seed()\n",
        "    torch.manual_seed(seed)\n",
        "    xl_base_pipe = \"runwayml/stable-diffusion-v1-5\"\n",
        "    pipe = model_pipe(xl_base_pipe)\n",
        "    image = pipe(\n",
        "        prompt=prompt,\n",
        "        height=height,\n",
        "        width=width,\n",
        "        num_inference_steps=n_steps,\n",
        "        negative_prompt=negative_prompt,\n",
        "        num_images_per_prompt=num_samples,\n",
        "        guidance_scale=guidance_scale,\n",
        "        generator=generator,\n",
        "    ).images[0]\n",
        "    story = sanitize_filename(story.strip())\n",
        "    try:\n",
        "      image.save(f\"{story}-{seed}.png\")\n",
        "    except OSError as e:\n",
        "        print(f\"Error saving with sanitized filename: {e}\")\n",
        "        image.save(f\"Image-{seed}.png\")\n",
        "    del pipe\n",
        "    torch.cuda.empty_cache()\n",
        "    return image\n",
        "\n",
        "\n",
        "def sanitize_filename(filename, char_limit=100):\n",
        "    # Define a dictionary to map invalid characters to their replacements\n",
        "    replace_dict = {\n",
        "        '\\\\': '-',\n",
        "        '\\n': '-',\n",
        "        '/': '-',\n",
        "        ':': '¦',\n",
        "        '*': '¤',\n",
        "        '?': '¿',\n",
        "        '\"': 'ˮ',\n",
        "        '<': '«',\n",
        "        '>': '»',\n",
        "        '|': '│',\n",
        "    }\n",
        "\n",
        "    # Replace invalid characters with their corresponding replacements\n",
        "    for char, replacement in replace_dict.items():\n",
        "        filename = filename.replace(char, replacement)\n",
        "    # Limit the filename to a certain number of characters\n",
        "    if len(filename) > char_limit:\n",
        "        limited_filename = filename[:char_limit]\n",
        "    else:\n",
        "        limited_filename = filename\n",
        "    return limited_filename\n",
        "\n",
        "\n",
        "def remove_background(img):\n",
        "    return rembg.remove(img)"
      ],
      "metadata": {
        "id": "IN2oDRSABbvz"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title call_txt_ai.py\n",
        "# call_txt_ai.py\n",
        "import requests\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "import torch\n",
        "import random\n",
        "\n",
        "def load_lamini_cpu(model_name_or_path, prompt):\n",
        "    # model_name_or_path = \"MBZUAI/LaMini-T5-738M\"\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, use_fast=True)\n",
        "    input_ids = tokenizer(prompt, return_tensors='pt').input_ids\n",
        "    loaded_model = AutoModelForSeq2SeqLM.from_pretrained(model_name_or_path)\n",
        "    return loaded_model, input_ids, tokenizer\n",
        "\n",
        "def load_CodeLlama_7B(model_name_or_path, prompt):\n",
        "    # model_name_or_path = \"TheBloke/CodeLlama-7B-Instruct-GPTQ\"\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, use_fast=True)\n",
        "    input_ids = tokenizer(prompt, return_tensors='pt').input_ids.cuda()\n",
        "    loaded_model = AutoModelForCausalLM.from_pretrained(model_name_or_path,\n",
        "                                                         device_map=\"auto\",\n",
        "                                                         trust_remote_code=True,\n",
        "                                                         revision=\"main\")\n",
        "    return loaded_model, input_ids, tokenizer\n",
        "\n",
        "def call_txt_ai_local_AutoGPTQ(prompt, max_tokens):\n",
        "    # Load the model if it's not already loaded\n",
        "    model_name_or_path = \"TheBloke/CodeLlama-7B-Instruct-GPTQ\"\n",
        "    loaded_model, input_ids, tokenizer = load_CodeLlama_7B(model_name_or_path, prompt)\n",
        "    # generator = torch.Generator(device='cpu')\n",
        "    # seed = generator.seed()\n",
        "    seed = random.randint(0, 2**16 - 1)\n",
        "    torch.manual_seed(seed)\n",
        "    output = loaded_model.generate(\n",
        "        inputs=input_ids,\n",
        "        do_sample=True,\n",
        "        temperature=0.8,\n",
        "        top_p=0.4,\n",
        "        top_k=40,\n",
        "        max_new_tokens=max_tokens, # Ignores words in prompt\n",
        "        min_new_tokens=10,\n",
        "        repetition_penalty=1.15,\n",
        "        max_time=3000,\n",
        "        # max_length=max_tokens, # Includes words in prompt\n",
        "    )\n",
        "    generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "    # Manually remove the prompt from the generated text\n",
        "    if generated_text.startswith(prompt):\n",
        "        generated_text = generated_text[len(prompt):].strip()\n",
        "    del loaded_model\n",
        "    torch.cuda.empty_cache()\n",
        "    return generated_text"
      ],
      "metadata": {
        "cellView": "form",
        "id": "fUJp196kF4YU"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title text_ai_helper.py\n",
        "# text_ai_helper.py\n",
        "import re\n",
        "\n",
        "\n",
        "def generate_prompt_items(item_type, max_items, story, num_type):\n",
        "    if num_type == 1:\n",
        "        prompt = f\"One answer for one instruction.\\n\" \\\n",
        "                 f\"Instruction: Write only a list with exactly {max_items} {item_type}. The list must have this format: \" \\\n",
        "                 f\"{item_type}1;{item_type}2;{item_type}3;...;{item_type}{max_items}\\n\" \\\n",
        "                 f\"The {item_type} should be based on this story: {story}.\\n\" \\\n",
        "                 f\"Answer:\"\n",
        "    elif num_type == 2:\n",
        "        prompt = f\"One answer for one instruction.\\n\" \\\n",
        "                 f\"Instruction: Construct a list that consists of precisely {max_items} {item_type}. The required format for the list is: \" \\\n",
        "                 f\"{item_type}1;{item_type}2;{item_type}3;...;{item_type}{max_items}\\n\" \\\n",
        "                 f\"The {item_type} you include should be influenced by the narrative of {story}.\\n\" \\\n",
        "                 f\"Answer:\"\n",
        "    else:\n",
        "        prompt = f\"One answer for one instruction.\\n\" \\\n",
        "                 f\"Instruction: Compose a list comprising {max_items} {item_type} exactly. The list format must adhere to this pattern: \" \\\n",
        "                 f\"{item_type}1; {item_type}2; {item_type}3; ...;{item_type}{max_items}\\n\" \\\n",
        "                 f\"The {item_type} you include should be related to the story of {story}.\\n\" \\\n",
        "                 f\"Answer:\"\n",
        "    return prompt\n",
        "\n",
        "\n",
        "def generate_prompt_items_with_list(item_type, item_list, story, max_attributes, num_type):\n",
        "    if num_type == 1:\n",
        "        prompt = f\"One answer for one instruction.\\n\" \\\n",
        "                 f\"Use this original list as a reference: {item_list}\\n\" \\\n",
        "                 f\"Instruction: Create a list containing {max_attributes} {item_type} for each item in the list, related to the story: '{story}'. \" \\\n",
        "                 f\"Use only this format to answer: \" \\\n",
        "                 f\"'{item_list[0]}:{item_type}1,...,{item_type}{max_attributes};{item_list[1]}:{item_type}1,...,{item_type}{max_attributes};...;{item_list[len(item_list) - 1]}:{item_type}1,...,{item_type}{max_attributes}'\\n\" \\\n",
        "                 f\"Answer:\"\n",
        "    elif num_type == 2:\n",
        "        prompt = f\"One answer for one instruction.\\n\" \\\n",
        "                 f\"Use this original list as a reference: {item_list}\\n\" \\\n",
        "                 f\"Instruction: Create a list containing one or two {item_type} for each item in the list, related to the story: '{story}'. \" \\\n",
        "                 f\"Use only this format to answer: \" \\\n",
        "                 f\"'{item_list[0]}:{item_type}1,{item_type}2;{item_list[1]}:{item_type}1,{item_type}2;...;{item_list[len(item_list) - 1]}:{item_type}1,{item_type}2'\\n\" \\\n",
        "                 f\"Answer:\"\n",
        "    else:\n",
        "        prompt = f\"One answer for one instruction.\\n\" \\\n",
        "                 f\"Use this original list as a reference: {item_list}\\n\" \\\n",
        "                 f\"Instruction: Create a list containing one {item_type} for each item in the list, related to the story: '{story}'. \" \\\n",
        "                 f\"Use only this format to answer: \" \\\n",
        "                 f\"'{item_list[0]}:{item_type};{item_list[1]}:{item_type};...;{item_list[len(item_list) - 1]}:{item_type}'\\n\" \\\n",
        "                 f\"Answer:\"\n",
        "    return prompt\n",
        "\n",
        "\n",
        "def generate_prompt_bg(story, length, num_type):\n",
        "    if num_type == 1:\n",
        "        prompt = f\"One answer for one instruction.\\n\" \\\n",
        "                 f\"Instruction: Create a description of the background related to this story: {story}.\\n\" \\\n",
        "                 f\"detail the scene of a horizontal close view canvas \" \\\n",
        "                 f\"use less than {length} words.\\n\" \\\n",
        "                 f\"Answer:\"\n",
        "    elif num_type == 2:\n",
        "        prompt = f\"One answer for one instruction.\\n\" \\\n",
        "                 f\"Instruction: Create a description of a background related to the story: {story}.\\n\" \\\n",
        "                 f\"not too far away, I need to see objects complexity, \"\\\n",
        "                 f\"Use less than {length*0.8} words.\\n\" \\\n",
        "                 f\"Answer:\"\n",
        "    else:\n",
        "        prompt = f\"One answer for one instruction.\\n\" \\\n",
        "                 f\"Instruction: Create a description of a background related to the story: {story}.\\n\" \\\n",
        "                 f\"Use less than {length*4} chars.\\n\" \\\n",
        "                 f\"Answer:\"\n",
        "    return prompt\n",
        "\n",
        "\n",
        "def extract_list(input_text, max_items):\n",
        "    input_text = input_text.strip(\"[\").strip(\"]\").strip(\"\\'\").strip(\"\\\"\").strip(\"{\").strip(\"}\").replace(\"  \", \" \") \\\n",
        "        .replace(\" ;\", \";\").replace(\"; \", \";\").strip(\":\").strip(\"\\\\n\").strip().replace(\"Answer: \", \";\").replace(\n",
        "        \"Answer:\", \";\")\n",
        "    extracted_list = input_text.split(';')\n",
        "    if not extracted_list or len(extracted_list) <= 1:\n",
        "        print(\"Incorrect format of input object validate_and_parse_list(): \" + input_text)\n",
        "        return None\n",
        "    # Limit the number of items in the list based on max_items\n",
        "    if max_items is not None:\n",
        "        extracted_list = extracted_list[:max_items]\n",
        "    # Remove items with more than 4 words\n",
        "    extracted_list = [item for item in extracted_list if len(item.split()) <= 4]\n",
        "    # Extract unique ones\n",
        "    unique_list = list(set(extracted_list))\n",
        "    return unique_list\n",
        "\n",
        "\n",
        "def extract_object_from_list(input_list, max_attributes):\n",
        "    try:\n",
        "        input_list = input_list.strip(\"[\").strip(\"]\").strip(\"\\'\").strip(\"\\\"\").strip(\"{\").strip(\"}\").replace(\"  \", \" \") \\\n",
        "            .replace(\" ;\", \";\").replace(\"; \", \";\").strip(\".\").strip()\n",
        "        pairs = input_list.split(';')\n",
        "        if not pairs or len(pairs) < 1:\n",
        "            raise ValueError(\"Incorrect format of input object validate_and_parse_list(): \" + input_list)\n",
        "        pairs = pairs[:len(input_list)]\n",
        "        extracted_object = {}\n",
        "        for pair in pairs:\n",
        "            # Split each pair by a colon to separate name and attributes\n",
        "            name, attributes_str = pair.split(':')\n",
        "            # Split the attributes by commas and create a list\n",
        "            attributes = attributes_str.split(',')\n",
        "            # Check if max_attributes is specified and limit the number of attributes\n",
        "            if max_attributes is not None:\n",
        "                attributes = attributes[:max_attributes]\n",
        "            # Remove attributes with more than 3 words\n",
        "            attributes = [attr for attr in attributes if len(attr.split()) <= 4]\n",
        "            # Add the name and attributes to the result dictionary\n",
        "            extracted_object[name] = attributes\n",
        "        return extracted_object\n",
        "    except ValueError as e:\n",
        "        print(str(e) + input_list)\n",
        "        return None\n",
        "\n",
        "\n",
        "def create_list_with_call_ai(item_type, max_items, story, prompt_type, retries=3):\n",
        "    if retries <= 0:\n",
        "        print(\"Error creating list with create_list_with_call_ai()\\n\")\n",
        "        return None\n",
        "    prompt = generate_prompt_items(item_type, max_items, story, prompt_type)\n",
        "    result = call_txt_ai_local_AutoGPTQ(prompt)\n",
        "    if result:\n",
        "        extracted_result = extract_list(result, max_items)\n",
        "        if extracted_result and max_items * 0.8 < len(extracted_result) < max_items * 1.2:\n",
        "            return extracted_result\n",
        "    # Retry with the next prompt type\n",
        "    return create_list_with_call_ai(item_type, max_items, story, prompt_type + 1, retries - 1)\n",
        "\n",
        "\n",
        "def create_object_with_call_ai(item_type, list_names, story, prompt_type, max_attributes=2, retries=3):\n",
        "    if retries <= 0:\n",
        "        print(\"Error creating object with create_object_with_call_ai()\\n\")\n",
        "        return None\n",
        "    prompt = generate_prompt_items_with_list(item_type, list_names, story, max_attributes, prompt_type)\n",
        "    result = call_txt_ai_local_AutoGPTQ(prompt)\n",
        "    if result:\n",
        "        items_quality = extract_object_from_list(result, max_attributes)\n",
        "        if items_quality and len(items_quality) > 0:\n",
        "            return items_quality\n",
        "    # Retry with the next prompt type\n",
        "    return create_object_with_call_ai(item_type, list_names, story, prompt_type + 1, retries - 1)\n",
        "\n",
        "\n",
        "def validate_description(description, max_word_count=100):\n",
        "    # Remove special characters and extra spaces\n",
        "    description = re.sub(r'[^\\w\\s]', '', description)\n",
        "    words = description.split()\n",
        "    # Check the word count\n",
        "    if len(words) > max_word_count*1.2:\n",
        "        print(\"Error creating description: Exceeds the maximum word count.\")\n",
        "        return None\n",
        "    elif len(description) < 5:\n",
        "        print(\"Error creating description: It's empty\")\n",
        "        return None\n",
        "    # Additional validation checks can be added here as needed\n",
        "    return ' '.join(words)\n",
        "\n",
        "\n",
        "def generate_bg_description(story, length, prompt_type, retries=3):\n",
        "    if retries <= 0:\n",
        "        print(\"Error creating background description\\n\")\n",
        "        return None\n",
        "    prompt = generate_prompt_bg(story, length, prompt_type)\n",
        "    result = call_txt_ai_local_AutoGPTQ(prompt, length)\n",
        "    if result:\n",
        "        bg_description = validate_description(result, length)\n",
        "        if bg_description:\n",
        "            return bg_description\n",
        "    # Retry with the next prompt type\n",
        "    return generate_bg_description(story, length, prompt_type + 1, retries - 1)\n",
        "\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "B7doi8f9F9Pb"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Background.py\n",
        "# Background.py\n",
        "class Background:\n",
        "    def __init__(self, description=None, max_width=None, max_height=None, image=None):\n",
        "        self._description = description\n",
        "        self._max_width = max_width\n",
        "        self._max_height = max_height\n",
        "        self._image = image\n",
        "\n",
        "    # Getter for description\n",
        "    def get_description(self):\n",
        "        return self._description\n",
        "\n",
        "    # Setter for description\n",
        "    def set_description(self, description):\n",
        "        self._description = description\n",
        "\n",
        "    # Getter for max width\n",
        "    def get_max_width(self):\n",
        "        return self._max_width\n",
        "\n",
        "    # Setter for max width\n",
        "    def set_max_width(self, max_width):\n",
        "        self._max_width = max_width\n",
        "\n",
        "    # Getter for max height\n",
        "    def get_max_height(self):\n",
        "        return self._max_height\n",
        "\n",
        "    # Setter for max height\n",
        "    def set_max_height(self, max_height):\n",
        "        self._max_height = max_height\n",
        "\n",
        "    def generate_image(self):\n",
        "        # Background image generation logic here\n",
        "        pass\n",
        "\n",
        "    # Getter for image\n",
        "    def get_image(self):\n",
        "        return self._image\n",
        "\n",
        "    # Setter for image\n",
        "    def set_image(self, image):\n",
        "        self._image = image\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "TJia2nH3HdfG"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Character.py\n",
        "# Character.py\n",
        "class Character:\n",
        "    def __init__(self, name, actions=None, appearance_modifiers=None,\n",
        "                 background_description=None, position=(0, 0), image=None):\n",
        "        self._name = name\n",
        "        self._actions = actions if actions is not None else []\n",
        "        self._appearance_modifiers = appearance_modifiers if appearance_modifiers is not None else []\n",
        "        self._background_description = background_description if background_description is not None else []\n",
        "        self._position = position\n",
        "        self._image = image\n",
        "\n",
        "    # Getter for name\n",
        "    def get_name(self):\n",
        "        return self._name\n",
        "\n",
        "    # Setter for name\n",
        "    def set_name(self, name):\n",
        "        self._name = name\n",
        "\n",
        "    # Getter for actions\n",
        "    def get_actions(self):\n",
        "        return self._actions\n",
        "\n",
        "    # Add an action to the character\n",
        "    def add_action(self, action):\n",
        "        if isinstance(action, list):\n",
        "            self._appearance_modifiers.extend(action)\n",
        "        else:\n",
        "            self._appearance_modifiers.append(action)\n",
        "\n",
        "    # Getter for appearance modifiers\n",
        "    def get_appearance_modifiers(self):\n",
        "        return self._appearance_modifiers\n",
        "\n",
        "    # Add an appearance modifier to the character (adjectives)\n",
        "    def add_appearance_modifier(self, modifier):\n",
        "        if isinstance(modifier, list):\n",
        "            self._appearance_modifiers.extend(modifier)\n",
        "        else:\n",
        "            self._appearance_modifiers.append(modifier)\n",
        "\n",
        "    # Getter for background description\n",
        "    def get_background_description(self):\n",
        "        return self._background_description\n",
        "\n",
        "    # Setter for background description\n",
        "    def set_background_description(self, description):\n",
        "        self._background_description = description\n",
        "\n",
        "    # Getter for position\n",
        "    def get_position(self):\n",
        "        return self._position\n",
        "\n",
        "    # Setter for position\n",
        "    def set_position(self, x, y):\n",
        "        self._position = (x, y)\n",
        "\n",
        "    def generate_image(self):\n",
        "        # Image generation logic here\n",
        "        pass\n",
        "\n",
        "    # Getter for image\n",
        "    def get_image(self):\n",
        "        return self._image\n",
        "\n",
        "    # Setter for image\n",
        "    def set_image(self, image):\n",
        "        self._image = image\n",
        "\n",
        "    def get_description(self):\n",
        "        name = self.get_name()\n",
        "        appearance_modifiers = \", \".join(self.get_appearance_modifiers()) if self.get_appearance_modifiers() else \"\"\n",
        "        actions = \", \".join(self.get_actions()) if self.get_actions() else \"\"\n",
        "        # Check if appearance_modifiers and actions are not empty\n",
        "        if appearance_modifiers and actions:\n",
        "            description = f\"{name}, {appearance_modifiers}, {actions}\"\n",
        "        elif appearance_modifiers:\n",
        "            description = f\"{name}, {appearance_modifiers}\"\n",
        "        elif actions:\n",
        "            description = f\"{name}, {actions}\"\n",
        "        else:\n",
        "            description = name\n",
        "        return description\n",
        "\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "At3KUK9cHiow"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title generation.py\n",
        "# generation.py\n",
        "\n",
        "\n",
        "def create_characters(story, max_items):\n",
        "    list_names = create_list_with_call_ai(\"names\", max_items, story, 1)\n",
        "    characters = []\n",
        "    if list_names:\n",
        "        print(list_names)\n",
        "        print('List length:', len(list_names))\n",
        "        characters = [Character(name) for name in list_names]\n",
        "        characters = create_appearance_modifiers(characters, story)\n",
        "        characters = create_actions(characters, story)\n",
        "        characters = create_images(characters)\n",
        "    return characters\n",
        "\n",
        "\n",
        "def create_appearance_modifiers(characters, story):\n",
        "    object_names_adjective = create_object_with_call_ai(\n",
        "        \"adjective\", [character.get_name() for character in characters], story, 1, 2)\n",
        "    if object_names_adjective:\n",
        "        print(object_names_adjective)\n",
        "        for character in characters:\n",
        "            name = character.get_name()\n",
        "            if name in object_names_adjective:\n",
        "                character.add_appearance_modifier(object_names_adjective[name])\n",
        "    return characters\n",
        "\n",
        "\n",
        "def create_actions(characters, story):\n",
        "    object_names_actions = create_object_with_call_ai(\n",
        "        \"actions\", [character.get_name() for character in characters], story, 1, 1)\n",
        "    if object_names_actions:\n",
        "        print(object_names_actions)\n",
        "        for character in characters:\n",
        "            name = character.get_name()\n",
        "            if name in object_names_actions:\n",
        "                character.add_action(object_names_actions[name])\n",
        "    return characters\n",
        "\n",
        "\n",
        "def create_images(characters):\n",
        "    for character in characters:\n",
        "        image = generate_character_image(character.get_description())\n",
        "        if image:\n",
        "            character.set_image(image)\n",
        "    return characters\n",
        "\n",
        "\n",
        "def create_background(story, width, height, story_length_description=300):\n",
        "    bg_description = create_bg_description(story, story_length_description)\n",
        "    if bg_description:\n",
        "        bg = Background(bg_description, width, height)\n",
        "    else:\n",
        "        print(\"Background description couldn't be created\")\n",
        "        return None\n",
        "    bg_img = create_bg_img(bg)\n",
        "    if bg_img:\n",
        "        bg.set_image(bg_img)\n",
        "    return bg\n",
        "\n",
        "\n",
        "def create_bg_description(story, length):\n",
        "    bg_description = generate_bg_description(story, length, 1)\n",
        "    if bg_description:\n",
        "        return bg_description\n",
        "    return None\n",
        "\n",
        "\n",
        "def create_bg_img(bg):\n",
        "    bg_img = generate_bg_image(bg.get_description(), bg.get_max_width(), bg.get_max_height())\n",
        "    if bg_img:\n",
        "        return bg_img\n",
        "    return None\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "XvKq5KrCHRWq"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title main\n",
        "from PIL import Image\n",
        "\n",
        "story = \"medieval castle era\"\n",
        "max_items = 3\n",
        "torch.cuda.empty_cache()\n",
        "# characters = create_characters(story, max_items)\n",
        "# print(characters[0].get_description())\n",
        "bg = create_background(story, 872, 512, 70)\n",
        "if bg:\n",
        "  print(bg.get_description())\n",
        "  bg.get_image\n"
      ],
      "metadata": {
        "id": "2d6R1RwmHszr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121,
          "referenced_widgets": [
            "acf06db2a7dd4634bfc1f5bddf87b9b7",
            "130102dcee2940c5b82e0436f3d6574d",
            "efa4b511f84e4a949f850306385ecaa3",
            "120fbe5def1d42f18e55d68530e83b12",
            "780280082f9c41e3b12c7d38d57edd3f",
            "05d5f48f674449ff82bc7be0c3e2f25c",
            "40f34c9283494c39b9abbbfd0ccf0d98",
            "aa230c54985842efb51c51789a7ad1fc",
            "9b66b584c24f436b9f72a936cbf56d32",
            "e1f364a47f754f45899cfc5bdbd630ec",
            "0d74383f6ff046b6aae06fc6b0c29d9e"
          ]
        },
        "outputId": "b6b468d9-4081-4d2a-c948-ea4bfe69cb9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "acf06db2a7dd4634bfc1f5bddf87b9b7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
            "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"bos_token_id\"]` will be overriden.\n",
            "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"eos_token_id\"]` will be overriden.\n"
          ]
        }
      ]
    }
  ]
}